<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>SharinGAN | Mohammad</title>
    <meta name="author" content="Mohammad  Nazeri">
    <meta name="description" content="Hello there, I'm Mohammad. Welcome to my page!!!
">
    <meta name="keywords" content="deep-learning, computer-vision, robotics, imitation-learning, social-navigation">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img//icon/icon.svg">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://mhnazeri.github.io/blog/2020/sharinGAN/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Mohammad</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">SharinGAN</h1>
    <p class="post-meta">July 29, 2020</p>
    <p class="post-tags">
      <a href="/blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a>
        ·  
        <a href="/blog/tag/computer-vision">
          <i class="fas fa-hashtag fa-sm"></i> computer_vision</a>  
          <a href="/blog/tag/generative">
          <i class="fas fa-hashtag fa-sm"></i> generative</a>  
          
        ·  
        <a href="/blog/category/programming">
          <i class="fas fa-tag fa-sm"></i> programming</a>  
          

    </p>
  </header>

  <article class="post-content">
    <p>Generative models especially with the emerge of <a href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="external nofollow noopener noopener noreferrer" target="_blank">Generative Adversarial Networks (GANs)</a> have become the spotlight of Deep Learning in recent years. They have <a href="https://github.com/nashory/gans-awesome-applications" rel="external nofollow noopener noopener noreferrer" target="_blank">many applications in the wild</a> and sometimes they are just for <a href="https://theaisummer.com/deepfakes/" rel="external nofollow noopener noopener noreferrer" target="_blank">fun</a>.
One fun application that I really liked, was the use of GAN to generate <a href="https://www.youtube.com/watch?v=8fnynVsR53k" rel="external nofollow noopener noopener noreferrer" target="_blank">fake Sharingans</a> (to read more about what Sharingan is please read <a href="https://naruto.fandom.com/wiki/Sharingan" rel="external nofollow noopener noopener noreferrer" target="_blank">this article</a>). Inspired by that video and PyTorch’s <a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="external nofollow noopener noopener noreferrer" target="_blank">DCGAN tutorial</a>, in this post I’m going to show you how to generate sharingans step by step. You can download the PyTorch source code from <a href="https://github.com/mhnazeri/sharingan" rel="external nofollow noopener noopener noreferrer" target="_blank">here</a>. I highly recommend downloading the full source code because here I only explain important steps in writing a DL model, things such as config files are not discussed here. To read more about project configuration see my <a href="https://mhnazeri.github.io/blog/2020/parameter_management/">Hyper-parameter Management</a> article.</p>

<p>To train a model, you have to address three stages:</p>
<ul>
  <li>Gathering and loading data</li>
  <li>Designing the architecture</li>
  <li>Loss function and train loop</li>
</ul>

<p>I structured my project directory as follows (if you like the structure, I created a template <a href="https://github.com/mhnazeri/ml_template" rel="external nofollow noopener noopener noreferrer" target="_blank">here</a>):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> └── sharinGAN/ 
 │  └──── conf/ 
 │  │  └──── optimizer/ 
 │  │  │  └──── adam.yaml  
 │  │  ├──── config.yaml  
 │  │  ├──── dirs.yaml  
 │  │  ├──── models.yaml  
 │  │  └──── train.yaml  
 │  └──── model/ 
 │  │  ├──── data_loader.py  
 │  │  ├──── __init__.py  
 │  │  └──── net.py  
 │  └──── sharingan_pics/ 
 │  │  ├──── 0.jpeg  
 │  │  ├──── 10.jpeg  
 │  │  ├──── ...
 │  ├──── train.py  
 │  └──── utils.py   
 ├── README.md  
 └── requirements.txt
</code></pre></div></div>

<h1 id="gathering-and-loading-data">Gathering and Loading Data</h1>
<p>The first thing that we need, in every problem that we are going to solve with deep learning, is <em>data</em>. I gathered some Sharingan pictures from google image search. It is a fairly easy task, you just need to search for the keyword <code class="language-plaintext highlighter-rouge">sharingan</code> and save the pictures in a folder. I named mine <code class="language-plaintext highlighter-rouge">sharing_pics</code>. So now, we have to write the <code class="language-plaintext highlighter-rouge">data_loader</code>.</p>

<p>To do so, first, we need to import the required libraries. We need <code class="language-plaintext highlighter-rouge">pathlib</code> to read image directories, <code class="language-plaintext highlighter-rouge">PIL</code>, Python imaging library (hence the name) to read images from the disk, PyTorch’s abstract <code class="language-plaintext highlighter-rouge">Dataset</code> module to write a class which handles concurrent reading and preprocessing for us, and finally for loading the config files we use a custom function that resides in <code class="language-plaintext highlighter-rouge">utils.py</code> file:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">omegaconf</span> <span class="kn">import</span> <span class="n">OmegaConf</span>


<span class="k">def</span> <span class="nf">get_conf</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">.yaml</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cfg</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">get_conf</span>


<span class="k">class</span> <span class="nc">SharinganDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># get data directory
</span>        <span class="n">data_dir</span> <span class="o">=</span> <span class="nf">get_conf</span><span class="p">(</span><span class="sh">"</span><span class="s">conf/dirs</span><span class="sh">"</span><span class="p">).</span><span class="n">train_data</span>
        <span class="c1"># store filenames
</span>        <span class="c1"># Path().iterdir() returns a generator, convert it to list
</span>        <span class="n">self</span><span class="p">.</span><span class="n">filenames</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nc">Path</span><span class="p">(</span><span class="n">data_dir</span><span class="p">).</span><span class="nf">iterdir</span><span class="p">())</span>
        <span class="n">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">return size of dataset</span><span class="sh">"""</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">filenames</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="c1"># load the image
</span>        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">filenames</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="c1"># apply transformers on it and return it
</span>        <span class="n">image</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span>
</code></pre></div></div>
<p>In <code class="language-plaintext highlighter-rouge">SharinganDataset</code> we read image addresses and store them in <code class="language-plaintext highlighter-rouge">self.filenames</code>. Our dataset size is the length of <code class="language-plaintext highlighter-rouge">self.filenames</code>, which in our case is <code class="language-plaintext highlighter-rouge">100</code>. Every image that we want to read, it’s address is in <code class="language-plaintext highlighter-rouge">self.filenames</code>, we read the image with the help of <code class="language-plaintext highlighter-rouge">PIL</code> and then apply image transformations on it. Finally, the image is in the form that we want. In the train loop section, we will discuss these transformations. And that’s it for loading data.</p>

<h1 id="designing-the-architecture">Designing the Architecture</h1>
<p>For the generator and discriminator architecture, we follow the <a href="https://arxiv.org/pdf/1511.06434.pdf" rel="external nofollow noopener noopener noreferrer" target="_blank">DCGAN</a> architecture and implement it as described in <a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="external nofollow noopener noopener noreferrer" target="_blank">pytorch tutorial</a> with one exception that <code class="language-plaintext highlighter-rouge">BatchNorm2d</code> is applied after the activation function. The code for model architectures resides in <code class="language-plaintext highlighter-rouge">model/net.py</code>. The noticeable network components here are:</p>
<ul>
  <li>
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html" rel="external nofollow noopener noopener noreferrer" target="_blank"><code class="language-plaintext highlighter-rouge">ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias)</code></a>: sometimes called <em>deconvolution</em> operator. But they are actually not the same. <code class="language-plaintext highlighter-rouge">ConvTranspose</code> applies filter on the spaced out (with zeros) input. The end result would be an upsampled of the input with learned weights.  You can read more about it <a href="https://arxiv.org/abs/1603.07285" rel="external nofollow noopener noopener noreferrer" target="_blank">here</a> with corresponding <a href="https://github.com/vdumoulin/conv_arithmetic" rel="external nofollow noopener noopener noreferrer" target="_blank">repo</a>. The output height can be calculated with: \(H_{out} =(H_{in} −1) \times stride[0]−2\times padding[0]+dilation[0]\times (kernel_size[0]−1)+outputpadding[0]+1\) and for the width: \(W_{out} =(W_{in}−1) \times stride[1]−2\times padding[1]+dilation[1]\times (kernel_size[1]−1)+outputpadding[1]+1\)</li>
  <li>
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html" rel="external nofollow noopener noopener noreferrer" target="_blank"><code class="language-plaintext highlighter-rouge">ReLU(inplace)</code></a>: as the activation function which is $max(0, x)$, and <code class="language-plaintext highlighter-rouge">inplace</code> is for doing the operation in-place in the output without using extra memory.</li>
  <li>
<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html" rel="external nofollow noopener noopener noreferrer" target="_blank"><code class="language-plaintext highlighter-rouge">BatchNorm2d(num_features)</code></a>:  which applies batch normalization on the input feature maps. You can read more about it <a href="https://arxiv.org/abs/1502.03167" rel="external nofollow noopener noopener noreferrer" target="_blank">here</a>.</li>
  <li>
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html" rel="external nofollow noopener noopener noreferrer" target="_blank"><code class="language-plaintext highlighter-rouge">Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias)</code></a>: is the convolution module.</li>
  <li>
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html" rel="external nofollow noopener noopener noreferrer" target="_blank"><code class="language-plaintext highlighter-rouge">LeakyRelU(negative_slope, inplace)</code></a>: is a derivative of <code class="language-plaintext highlighter-rouge">ReLU</code> which is not strictly hard on negative values. <code class="language-plaintext highlighter-rouge">negative_slope</code> is responsible for this softness.</li>
  <li>
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html" rel="external nofollow noopener noopener noreferrer" target="_blank"><code class="language-plaintext highlighter-rouge">Sigmoid()</code></a>: an activation function which squashed the output to be between $[0, 1]$ just like a probability.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">get_conf</span>


<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="nf">get_conf</span><span class="p">(</span><span class="sh">"</span><span class="s">conf/model/generator</span><span class="sh">"</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">gen</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="c1"># input is Z, going into a convolution
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">ConvTranspose2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">nz</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="c1"># state size. (ngf*8) x 4 x 4
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">ConvTranspose2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="c1"># state size. (ngf*4) x 8 x 8
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">ConvTranspose2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="c1"># state size. (ngf*2) x 16 x 16
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">ConvTranspose2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span><span class="p">),</span>
            <span class="c1"># state size. (ngf) x 32 x 32
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">ConvTranspose2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngf</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">nc</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Tanh</span><span class="p">()</span>
            <span class="c1"># state size. (nc) x 64 x 64
</span>        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">gen</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="nf">get_conf</span><span class="p">(</span><span class="sh">"</span><span class="s">conf/model/discriminator</span><span class="sh">"</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">dis</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="c1"># input is (nc) x 64 x 64
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">nc</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="c1"># state size. (ndf) x 32 x 32
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="c1"># state size. (ndf*2) x 16 x 16
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="c1"># state size. (ndf*4) x 8 x 8
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="c1"># state size. (ndf*8) x 4 x 4
</span>            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">ndf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> 
                <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">dis</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></div></div>

<p>The generator (from now on we call it <em>G</em>) is responsible for generating images like real Sharingans. Therefore, it’s output must be an image with the same size as the real images ((3, 64, 64) tensors). On the other side, the discriminator (<em>D</em>) is responsible to decide the authenticity of input images, it outputs <code class="language-plaintext highlighter-rouge">1</code> where the image is <em>real</em> and <code class="language-plaintext highlighter-rouge">0</code> where it is <em>fake</em>. Actually, the discriminator is not that accurate, it outputs the probability of the image being authentic. Where close to <code class="language-plaintext highlighter-rouge">1</code> means the discriminator is somewhat sure that the image is real and close to <code class="language-plaintext highlighter-rouge">0</code> means vice versa. That’s why we need a <code class="language-plaintext highlighter-rouge">Sigmoid()</code> function at the end of the discriminator. This takes us to the last part of this project which is defining the <em>loss function</em> and <em>training loop</em>.</p>

<h1 id="loss-function-and-train-loop">Loss function and Train loop</h1>
<p>GANs train a little different from normal networks. It is a zero-sum game between two networks where one tries to fool another to accept its outputs as authentic. The loss function, defined to do so, is called adversarial loss:</p>

\[min_G max_D log(D(x))+log(1−D(G(z)))\]

<p>You can read more about it in the <a href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="external nofollow noopener noopener noreferrer" target="_blank">original paper</a>:</p>

<p>This is very similar to binary cross-entropy where we have:</p>

\[ylog(x)+(1-y)log(1−x)\]

<p>Training GANs is very tricky, I suggest reading <a href="https://github.com/soumith/ganhacks" rel="external nofollow noopener noopener noreferrer" target="_blank">GAN hacks</a> page which contains useful information regarding training GANs. We split training into two parts, one for the discriminator and one for the generator.</p>

<h2 id="training-discriminator">Training Discriminator</h2>
<p>The sole purpose of the discriminator is to classify real and fake images with high probability. Which means we want to maximize \(log(D(x))+log(1−D(G(z)))\)
According to GAN hacks, we use two batches, one batch for true images and one for fake images. After forward pass of real images we label of <code class="language-plaintext highlighter-rouge">1</code>, we perform one <code class="language-plaintext highlighter-rouge">backward()</code> pass to calculate derivatives, then we pass fake (generated) images to <em>D</em> with label of <code class="language-plaintext highlighter-rouge">0</code> and perform another <code class="language-plaintext highlighter-rouge">backward()</code> pass to accumulate gradients and then update the weights.</p>

<h2 id="training-generator">Training Generator</h2>
<p>According to original paper <em>G</em> wants to minimize \(log(1−D(G(z)))\)
Minimizing this means fooling <em>D</em> to output high probability (<code class="language-plaintext highlighter-rouge">1</code> means they are real) therefor this part will descend to <code class="language-plaintext highlighter-rouge">0</code>. But in the early stages of training, this is very unlikely that the <em>D</em> discriminates well, as a result of this, <em>G</em> won’t get better. But instead maximizing \(log(D(G(z)))\) would solve this issue. To only use \(log(D(G(z)))\) part of binary cross-entropy we need to pass the label <code class="language-plaintext highlighter-rouge">1</code> with <em>G</em> outputs to the discriminator.</p>

<p>That’s it. There are just little modifications left in order to start the training. According to GAN hacks, initializing weights with normal distribution yield better results. To do so, we need a function to do this for us:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="c1"># get the module name
</span>    <span class="n">classname</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span>
    <span class="c1"># if it is in ['Conv', 'BatchNorm', 'Linear'], apply normal initialization
</span>    <span class="k">if</span> <span class="n">classname</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="sh">'</span><span class="s">Conv</span><span class="sh">'</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">classname</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="sh">'</span><span class="s">BatchNorm</span><span class="sh">'</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">constant_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">classname</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="sh">'</span><span class="s">Linear</span><span class="sh">'</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">constant_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>
<p>And here is the training loop, some functions are imported from <code class="language-plaintext highlighter-rouge">utils.py</code> that you can find in the source code:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="n">torchvision.utils</span> <span class="k">as</span> <span class="n">vutils</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">get_device</span><span class="p">,</span> <span class="n">plot_images</span><span class="p">,</span> <span class="n">weights_init</span><span class="p">,</span> <span class="n">get_conf</span>
<span class="kn">from</span> <span class="n">model.data_loader</span> <span class="kn">import</span> <span class="n">SharinganDataset</span>
<span class="kn">from</span> <span class="n">model.net</span> <span class="kn">import</span> <span class="n">Discriminator</span><span class="p">,</span> <span class="n">Generator</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="nf">get_conf</span><span class="p">(</span><span class="sh">"</span><span class="s">conf/train</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nf">get_device</span><span class="p">()</span>
    <span class="c1"># Create the generator
</span>    <span class="n">netG</span> <span class="o">=</span> <span class="nc">Generator</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Handle multi-gpu
</span>    <span class="nf">if </span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="nb">type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">netG</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">DataParallel</span><span class="p">(</span><span class="n">netG</span><span class="p">,</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngpu</span><span class="p">)))</span>

    <span class="c1"># Apply the weights_init function to randomly
</span>    <span class="c1"># initialize all weights to mean=0, stdev=0.2.
</span>    <span class="n">netG</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
    <span class="c1"># Create the Discriminator
</span>    <span class="n">netD</span> <span class="o">=</span> <span class="nc">Discriminator</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Handle multi-gpu if desired
</span>    <span class="nf">if </span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="nb">type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngpu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">netD</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">DataParallel</span><span class="p">(</span><span class="n">netD</span><span class="p">,</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">ngpu</span><span class="p">)))</span>

    <span class="c1"># Apply the weights_init function to randomly
</span>    <span class="c1"># initialize all weights to mean=0, stdev=0.2.
</span>    <span class="n">netD</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
    <span class="c1"># transform images: 
</span>    <span class="c1"># Resize to 64x64 -&gt; Center crop -&gt; Convert to tensor-&gt; normalize
</span>    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">Resize</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">CenterCrop</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
    <span class="p">])</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="nc">SharinganDataset</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                            <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                            <span class="n">num_workers</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">workers</span><span class="p">)</span>

    <span class="c1"># Initialize BCELoss function
</span>    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BCELoss</span><span class="p">()</span>

    <span class="c1"># Establish convention for real and fake labels during training
</span>    <span class="n">fixed_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span> 
                              <span class="n">cfg</span><span class="p">.</span><span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">real_label</span> <span class="o">=</span> <span class="mf">1.</span>
    <span class="n">fake_label</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="c1"># load adam optimizer's config
</span>    <span class="n">cfg_adam</span> <span class="o">=</span> <span class="nf">get_conf</span><span class="p">(</span><span class="sh">"</span><span class="s">conf/optimizer/adam</span><span class="sh">"</span><span class="p">)</span>
    <span class="c1"># Setup Adam optimizers for both G and D
</span>    <span class="n">optimizerD</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">netD</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> 
                            <span class="n">lr</span><span class="o">=</span><span class="n">cfg_adam</span><span class="p">.</span><span class="n">lr</span><span class="p">,</span> 
                            <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">cfg_adam</span><span class="p">.</span><span class="n">beta1</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>
    <span class="n">optimizerG</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">netG</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> 
                            <span class="n">lr</span><span class="o">=</span><span class="n">cfg_adam</span><span class="p">.</span><span class="n">lr</span><span class="p">,</span> 
                            <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">cfg_adam</span><span class="p">.</span><span class="n">beta1</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>
    <span class="c1"># Training Loop
</span>
    <span class="c1"># Lists to keep track of progress
</span>    <span class="n">img_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">G_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">D_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">iters</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Starting Training Loop...</span><span class="sh">"</span><span class="p">)</span>
    <span class="c1"># For each epoch
</span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="c1"># For each batch in the dataloader
</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>

            <span class="c1">############################
</span>            <span class="c1"># (1) Update D network: 
</span>            <span class="c1"># maximize log(D(x)) + log(1 - D(G(z)))
</span>            <span class="c1">###########################
</span>            <span class="c1">## Train with all-real batch
</span>            <span class="n">netD</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="c1"># send data batch to the device
</span>            <span class="n">real_cpu</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># get batch size
</span>            <span class="n">b_size</span> <span class="o">=</span> <span class="n">real_cpu</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># create labels for real images, 
</span>            <span class="c1"># we need labels for each image in the batch
</span>            <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">full</span><span class="p">((</span><span class="n">b_size</span><span class="p">,),</span> 
                               <span class="n">real_label</span><span class="p">,</span> 
                               <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">,</span> 
                               <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># Forward pass real batch through D
</span>            <span class="n">output</span> <span class="o">=</span> <span class="nf">netD</span><span class="p">(</span><span class="n">real_cpu</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Calculate loss on all-real batch
</span>            <span class="n">errD_real</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
            <span class="c1"># Calculate gradients of real batch for D in backward pass
</span>            <span class="n">errD_real</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">D_x</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>

            <span class="c1">## Train with all-fake batch
</span>            <span class="c1"># Generate batch of latent vectors
</span>            <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">b_size</span><span class="p">,</span> 
                                <span class="n">cfg</span><span class="p">.</span><span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># Generate fake image batch with G
</span>            <span class="n">fake</span> <span class="o">=</span> <span class="nf">netG</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
            <span class="n">label</span><span class="p">.</span><span class="nf">fill_</span><span class="p">(</span><span class="n">fake_label</span><span class="p">)</span>
            <span class="c1"># Classify all fake batch with D
</span>            <span class="c1"># we need to detch the computation graph here
</span>            <span class="c1"># because we don't want update G here
</span>            <span class="n">output</span> <span class="o">=</span> <span class="nf">netD</span><span class="p">(</span><span class="n">fake</span><span class="p">.</span><span class="nf">detach</span><span class="p">()).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Calculate D's loss on the all-fake batch
</span>            <span class="n">errD_fake</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
            <span class="c1"># Calculate the gradients of fake batch
</span>            <span class="c1"># for this batch (this gets accumulated)
</span>            <span class="n">errD_fake</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">D_G_z1</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
            <span class="c1"># Add the gradients from the all-real and
</span>            <span class="c1"># all-fake batches (just for visualization)
</span>            <span class="n">errD</span> <span class="o">=</span> <span class="n">errD_real</span> <span class="o">+</span> <span class="n">errD_fake</span>
            <span class="c1"># Update D
</span>            <span class="n">optimizerD</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

            <span class="c1">############################
</span>            <span class="c1"># (2) Update G network: maximize log(D(G(z)))
</span>            <span class="c1">###########################
</span>            <span class="n">netG</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">label</span><span class="p">.</span><span class="nf">fill_</span><span class="p">(</span><span class="n">real_label</span><span class="p">)</span>  <span class="c1"># fake labels are real for generator cost
</span>            <span class="c1"># Since we just updated D, perform another
</span>            <span class="c1"># forward pass of all-fake batch through D
</span>            <span class="n">output</span> <span class="o">=</span> <span class="nf">netD</span><span class="p">(</span><span class="n">fake</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Calculate G's loss based on this output
</span>            <span class="n">errG</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
            <span class="c1"># Calculate gradients for G
</span>            <span class="n">errG</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">D_G_z2</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
            <span class="c1"># Update G
</span>            <span class="n">optimizerG</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

            <span class="c1"># Output training stats
</span>            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">[%d/%d][%d/%d]</span><span class="se">\t</span><span class="s">Loss_D: %.4f</span><span class="se">\t</span><span class="s">Loss_G: %.4f</span><span class="se">\t</span><span class="s">D(x): %.4f</span><span class="se">\t</span><span class="s">D(G(z)): %.4f / %.4f</span><span class="sh">'</span>
                      <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">cfg</span><span class="p">.</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">),</span>
                         <span class="n">errD</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">errG</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">D_G_z2</span><span class="p">))</span>

            <span class="c1"># Save Losses for plotting later
</span>            <span class="n">G_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">errG</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
            <span class="n">D_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">errD</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>

            <span class="c1"># Check how the generator is doing by
</span>            <span class="c1"># saving G's output on fixed_noise
</span>            <span class="nf">if </span><span class="p">(</span><span class="n">iters</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">((</span><span class="n">epoch</span> <span class="o">==</span> <span class="n">cfg</span><span class="p">.</span><span class="n">num_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)):</span>
                <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
                    <span class="n">fake</span> <span class="o">=</span> <span class="nf">netG</span><span class="p">(</span><span class="n">fixed_noise</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">()</span>
                <span class="n">img_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">vutils</span><span class="p">.</span><span class="nf">make_grid</span><span class="p">(</span><span class="n">fake</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>

            <span class="n">iters</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>
<p>This is like normal training but with a little adjustment where we need to train both <em>D</em> and <em>G</em>.</p>

<h1 id="results">Results</h1>
<p>After 200 epochs the results are like this:</p>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_200-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_200-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_200-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_200.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<p>As you can see, the generator learns some patterns from the data. Of course, if you train it for more epochs, it gets better and better. One improvement (again according to GAN hacks) that we can add is to train <em>D</em> more than <em>G</em>. The notion behind it is that if <em>D</em> do its job perfectly, then <em>G</em> challenged and need to can change more to keep up.</p>

<p>I perform another modification on <em>D</em>’s loss. As the output of <em>D</em> is a probability, its gradients are small, as a result, the changes in weights will be minor. To make gradients bigger for bigger changes, I add squared distance of real images with fake images to the <em>D</em>’s loss with some weight $\beta$ (here $\beta=0.01$). So, the <em>D</em>’s loss becomes this:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">errD_fake</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">fake</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span> <span class="o">-</span> <span class="n">real_cpu</span><span class="p">).</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>
</code></pre></div></div>

<p>Although we should keep this in mind, the gradients should not get too big. In the next section, I will discuss how to prevent this. But for now, this modification yields this result for <code class="language-plaintext highlighter-rouge">1000</code> epochs:</p>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_modified_collapsed.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_modified_collapsed.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_modified_collapsed.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_modified_collapsed.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<p>As you can see here, the images getting better and better until they hit a wall and reset, and at the end, <em>G</em> only generate one Sharingan, that is because this pattern was able to fool <em>D</em> and <em>G</em> does not bother itself to generate another Sharingan. This situation is called <em>mode collapse</em> in GAN literature.</p>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_mod_loss-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_mod_loss-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_mod_loss-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_mod_loss.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<p>If we take a look at the loss functions of <em>D</em> and <em>G</em>, we can see two spikes in <em>D</em>’s loss. Those spikes are exactly where we see that generated images falling apart. <em>G</em> generates garbage and <em>D</em> can’t decide.</p>

<p>Back to where we need to prevent gradients from exploding. To prevent this, we can add gradient clipping in order to prevent the gradients going higher than a threshold. One option is to use gradient clipping (here <code class="language-plaintext highlighter-rouge">clipping_threshold_d = 5</code>) which should be added just before updating weights:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">clipping_threshold_d</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">clip_grad_norm_</span><span class="p">(</span><span class="n">netD</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span>
                                     <span class="n">clipping_threshold_d</span><span class="p">)</span>
<span class="c1"># Update D
</span><span class="n">optimizerD</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div>
<p>Another option is to add <a href="https://arxiv.org/abs/1802.05957" rel="external nofollow noopener noopener noreferrer" target="_blank">spectral normalization</a> to <em>D</em> to stabilize its training. I also added it to the <em>G</em> as well. To add this in code, when defining <em>G</em> and <em>D</em> components, instead of <code class="language-plaintext highlighter-rouge">ConvTranspose2d</code> and <code class="language-plaintext highlighter-rouge">Conv2d</code> add these:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">ConvTranspose2d</span><span class="p">(...))</span>
<span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(...))</span>
</code></pre></div></div>
<p>With these optimizations and without modified <em>D</em>’s loss, after 200 epochs we get:</p>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_mod_sn.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_mod_sn.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_mod_sn.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_mod_sn.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_200_mod-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_200_mod-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_200_mod-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_200_mod.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<p>Comparing the first run with the optimized version, we can see that in the latter, <em>G</em> does its best to generate Sharingans with different patterns. After 800 more epochs:</p>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_1000_mod.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_1000_mod.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_1000_mod.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_1000_mod.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_800-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_800-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_800-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_800.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<p><em>G</em> collapsed again but this time it has more variety.</p>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_loss_800-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_loss_800-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_loss_800-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_loss_800.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<p>Taking a look at the loss function we can see this time we’ve managed to prevent spikes in <em>D</em>’s loss. If we train the model with fewer epochs the collapse would not occur. So 1000 epochs are overkill for this small dataset as in early epochs we can see good results and we should stop the training there (early stopping).</p>

<p>And here is the result with optimizations and modified <em>D</em> loss function after 300 epochs (I didn’t train it more because as we saw above, it is likely would collapse):</p>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_mod_300.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_mod_300.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_mod_300.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_mod_300.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_mod_300-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_mod_300-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_mod_300-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_mod_300.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<p>And for the loss:</p>

<div class="row mt-3">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sharingan/sharingan_loss_mod_300-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sharingan/sharingan_loss_mod_300-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sharingan/sharingan_loss_mod_300-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/sharingan/sharingan_loss_mod_300.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</div>

<p>The loss is much better and more stable.</p>

<p>To be honest, with these low res images finding subtle patterns is difficult and <em>G</em> is doing a great job. For generating crystal clear Sharingan images we need improved derivatives of GAN. Hopefully, in future posts, I will talk about implementing them. And that’s it, I hope you enjoyed this post.</p>

  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/parameter_management/">Hyper-parameter Management in Deep Learning Projects</a>
  </li>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Mohammad  Nazeri. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener noopener noreferrer" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@/dist/medium-zoom.min.js" integrity="" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
